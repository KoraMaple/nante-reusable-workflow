name: "Reusable VM Provisioning"

on:
  workflow_call:
    inputs:
      app_name:
        type: string
        description: 'Application Name (e.g. nexus, k3s, octopus)'
        required: true
        default: 'app'
      vlan_tag:
        type: string
        description: 'Network Zone'
        default: '20'
      vm_target_ip:
        type: string
        description: 'Target IP Address'
        required: true
      cpu_cores:
        type: string
        description: 'CPU Cores'
        required: true
        default: '2'
      ram_mb:
        type: string
        description: 'RAM in MB'
        required: true
        default: '4096'
      disk_gb:
        type: string
        description: 'Disk Size (e.g. 20G)'
        required: true
        default: '20G'

jobs:
  provision:
    runs-on: self-hosted
    env:
      PM_API_TOKEN_ID: ${{ secrets.PROXMOX_TOKEN_ID }}
      PM_API_TOKEN_SECRET: ${{ secrets.PROXMOX_TOKEN_SECRET }}
    
    steps:
      - name: Checkout Reusable Workflow Repo
        uses: actions/checkout@v4
        with:
          repository: KoraMaple/nante-reusable-workflow
          ref: main
          token: ${{ secrets.GH_PAT }}

      - name: Validate VLAN and IP Match
        run: |
          VLAN="${{ inputs.vlan_tag }}"
          IP="${{ inputs.vm_target_ip }}"
          EXPECTED_PREFIX="192.168.${VLAN}."
          
          if [[ ! "$IP" == ${EXPECTED_PREFIX}* ]]; then
            echo "❌ Error: IP '$IP' does not match VLAN $VLAN (expected ${EXPECTED_PREFIX}x)"
            exit 1
          fi
          echo "✓ VLAN $VLAN and IP $IP are valid"

      - name: Terraform Plan
        env:
          TF_VAR_proxmox_api_url: ${{ secrets.PROXMOX_API_URL }}
          TF_VAR_proxmox_api_token_id: ${{ secrets.PROXMOX_TOKEN_ID }}
          TF_VAR_proxmox_api_token_secret: ${{ secrets.PROXMOX_TOKEN_SECRET }}
          TF_VAR_ssh_public_key: ${{ secrets.ANS_SSH_PUBLIC_KEY }}
        run: |
          # Ensure state directory exists (use home dir for runner permissions)
          mkdir -p $HOME/.terraform-state
          
          cd terraform/
          terraform init -backend-config="path=$HOME/.terraform-state/terraform.tfstate"
          
          # Select workspace or create it if it doesn't exist
          terraform workspace select ${{ inputs.app_name }} || terraform workspace new ${{ inputs.app_name }}
          
          terraform plan \
            -var="app_name=${{ inputs.app_name }}" \
            -var="vlan_tag=${{ inputs.vlan_tag }}" \
            -var="vm_target_ip=${{ inputs.vm_target_ip }}" \
            -var="vm_cpu_cores=${{ inputs.cpu_cores }}" \
            -var="vm_ram_mb=${{ inputs.ram_mb }}" \
            -var="vm_disk_gb=${{ inputs.disk_gb }}" \
            -out=tfplan

      - name: Terraform Apply
        env:
          TF_VAR_proxmox_api_url: ${{ secrets.PROXMOX_API_URL }}
          TF_VAR_proxmox_api_token_id: ${{ secrets.PROXMOX_TOKEN_ID }}
          TF_VAR_proxmox_api_token_secret: ${{ secrets.PROXMOX_TOKEN_SECRET }}
          TF_VAR_ssh_public_key: ${{ secrets.ANS_SSH_PUBLIC_KEY }}
        run: |
          cd terraform/
          terraform apply tfplan

      - name: Wait for VM to boot and SSH to be ready
        run: |
          echo "Waiting for VM at ${{ inputs.vm_target_ip }} to be reachable..."
          
          # Wait up to 2 minutes for the VM to respond
          for i in {1..24}; do
            if ping -c 1 -W 2 ${{ inputs.vm_target_ip }} &>/dev/null; then
              echo "✓ VM is responding to ping"
              break
            fi
            echo "Attempt $i/24: VM not yet reachable, waiting 5s..."
            sleep 5
          done
          
          # Wait for SSH port to be open
          echo "Waiting for SSH port 22..."
          for i in {1..12}; do
            if nc -z -w 2 ${{ inputs.vm_target_ip }} 22 2>/dev/null; then
              echo "✓ SSH port is open"
              exit 0
            fi
            echo "Attempt $i/12: SSH not ready, waiting 5s..."
            sleep 5
          done
          
          echo "⚠️ SSH may not be ready, proceeding anyway..."

      - name: Ansible Config
        env:
          TS_AUTHKEY: ${{ secrets.TS_AUTHKEY }}
          OO_USER: ${{ secrets.OO_USER }}
          OO_PASS: ${{ secrets.OO_PASS }}
          OO_HOST: ${{ secrets.OO_HOST }}
        run: |
          # 1. Create the temporary SSH key from secrets
          echo "${{ secrets.SSH_PRIVATE_KEY }}" > id_rsa_temp
          chmod 600 id_rsa_temp
          
          cd ansible/
          
          # Install requirements
          ansible-galaxy install -r requirements.yml
          
          # 2. Run the playbook using the IP from the manual UI input
          # We also pass the app_name so Ansible can set the OS hostname
          ansible-playbook -i "${{ inputs.vm_target_ip }}," site.yml \
            --user deploy \
            --private-key ../id_rsa_temp \
            --ssh-common-args='-o StrictHostKeyChecking=no' \
            --extra-vars "target_hostname=${{ inputs.app_name }}" \
            --extra-vars "vlan_tag=${{ inputs.vlan_tag }}" \
            --extra-vars "app_role_name=${{ inputs.app_name }}"

          # 3. Clean up the sensitive key file
          rm ../id_rsa_temp